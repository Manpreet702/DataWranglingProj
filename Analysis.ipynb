{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b434cf8a-c9d6-4c2a-85ce-038c546fa6f4",
   "metadata": {},
   "source": [
    "#### Data Wrangling Techniques Applied So Far The following Python code snippets (using the pandas library) illustrate the data preparation steps completed for RQ1 and RQ2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f10e3e5-8af5-4d7f-aa05-046f38902278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RQ2 Wrangling Snapshot:\n",
      "   pr_id  agent  patch_size  total_comments\n",
      "0      1   True          18               3\n",
      "1      2  False         150              10\n",
      "2      3   True          25               1\n",
      "3      4  False          60               5\n",
      "\n",
      "RQ1 Wrangling Snapshot (Aggregated):\n",
      "   agent  path_category  total_prs  accepted_prs  acceptance_rate\n",
      "0  False  Documentation          1             0              0.0\n",
      "1  False    Source Code          1             0              0.0\n",
      "2   True    Source Code          1             2              2.0\n",
      "3   True     Test Files          1             1              1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'pr_df' is pull_request, 'commit_df' is pr_commit_details\n",
    "# and 'repo_df' is repository, etc.\n",
    "\n",
    "# Sample data to demonstrate joins and feature creation\n",
    "pr_data = {\n",
    "    'id': [1, 2, 3, 4], \n",
    "    'repo_id': [101, 101, 102, 102],\n",
    "    'agent': [True, False, True, False],\n",
    "    'merged_at': ['2025-01-01', None, '2025-01-05', None],\n",
    "    'state': ['merged', 'closed', 'merged', 'closed']\n",
    "}\n",
    "pr_df = pd.DataFrame(pr_data)\n",
    "\n",
    "commit_data = {\n",
    "    'pr_id': [1, 1, 2, 3, 4],\n",
    "    'additions': [10, 5, 100, 20, 50],\n",
    "    'deletions': [2, 1, 50, 5, 10],\n",
    "    'file_path': ['src/main.py', 'src/util.py', 'docs/README.md', 'tests/test.py', 'src/func.js']\n",
    "}\n",
    "commit_df = pd.DataFrame(commit_data)\n",
    "\n",
    "comments_data = {\n",
    "    'pr_id': [1, 2, 3, 4],\n",
    "    'total_comments': [3, 10, 1, 5]\n",
    "}\n",
    "comments_df = pd.DataFrame(comments_data)\n",
    "\n",
    "\n",
    "## A. RQ2: Computing Patch Size and Total Comments\n",
    "# 1. Compute Patch Size (total changes) per PR\n",
    "patch_size_df = commit_df.groupby('pr_id').agg(\n",
    "    total_additions=('additions', 'sum'),\n",
    "    total_deletions=('deletions', 'sum')\n",
    ").reset_index()\n",
    "patch_size_df['patch_size'] = patch_size_df['total_additions'] + patch_size_df['total_deletions']\n",
    "\n",
    "# 2. Join patch size with comment counts\n",
    "rq2_df = pr_df.merge(patch_size_df[['pr_id', 'patch_size']], left_on='id', right_on='pr_id')\n",
    "rq2_df = rq2_df.merge(comments_df, left_on='id', right_on='pr_id', suffixes=('_pr', '_comm'))\n",
    "rq2_df = rq2_df[['id', 'agent', 'patch_size', 'total_comments']].rename(columns={'id': 'pr_id'})\n",
    "\n",
    "# Example of RQ2 wrangling result\n",
    "print(\"RQ2 Wrangling Snapshot:\")\n",
    "print(rq2_df.head())\n",
    "\n",
    "## B. RQ1: Defining Acceptance and Categorizing File Paths\n",
    "# 1. Define PR Acceptance (Target Variable)\n",
    "pr_df['accepted'] = pr_df['merged_at'].notna() # merged_at != NULL -> accepted \n",
    "\n",
    "# 2. Extract and Categorize File Paths\n",
    "def categorize_path(path):\n",
    "    \"\"\"Categorizes file path into high-level groups.\"\"\"\n",
    "    if path.startswith('src/'):\n",
    "        return 'Source Code'\n",
    "    elif path.startswith('docs/'):\n",
    "        return 'Documentation'\n",
    "    elif path.startswith('tests/'):\n",
    "        return 'Test Files'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "commit_df['path_category'] = commit_df['file_path'].apply(categorize_path)\n",
    "\n",
    "# 3. Join and Aggregate for RQ1 analysis\n",
    "# We aggregate the categories modified by each PR to get the main file type modified\n",
    "# Note: A PR can modify multiple file types. For simplicity here, we group by PR and its categories.\n",
    "rq1_data = commit_df.merge(pr_df[['id', 'agent', 'accepted']], left_on='pr_id', right_on='id')\n",
    "rq1_df = rq1_data.groupby(['agent', 'path_category']).agg(\n",
    "    total_prs=('id', 'nunique'),\n",
    "    accepted_prs=('accepted', 'sum')\n",
    ").reset_index()\n",
    "rq1_df['acceptance_rate'] = rq1_df['accepted_prs'] / rq1_df['total_prs']\n",
    "\n",
    "# Example of RQ1 wrangling result (aggregated counts)\n",
    "print(\"\\nRQ1 Wrangling Snapshot (Aggregated):\")\n",
    "print(rq1_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b07b51-2866-48ce-b65f-eea7f1fbd7a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb9f275c-53a6-48d9-83d7-f3d7d7e1c455",
   "metadata": {},
   "source": [
    "#### RQ2: Relationship between Patch Size and Review Comments\n",
    "##### The analysis modeled the relationship between Patch Size (total additions + deletions) and the Number of Review Comments. We used log-transformations for both variables to linearize the relationship and address heavy skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f8ca840-5f96-4447-a933-7b97048e72e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- RQ2 Results ---\n",
      "Spearman Rank Correlation (R): 0.800\n",
      "P-value: 0.200\n",
      "Regression Coefficient (Beta): 0.658\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Use wrangled RQ2 data for modeling\n",
    "# Apply log transformation (add 1 to handle zero values)\n",
    "rq2_df['log_patch_size'] = np.log1p(rq2_df['patch_size'])\n",
    "rq2_df['log_comments'] = np.log1p(rq2_df['total_comments'])\n",
    "\n",
    "# Calculate correlation\n",
    "correlation, p_value = stats.spearmanr(rq2_df['patch_size'], rq2_df['total_comments'])\n",
    "\n",
    "# Linear Regression Model (X = log_patch_size, Y = log_comments)\n",
    "X = sm.add_constant(rq2_df['log_patch_size'])\n",
    "model = sm.OLS(rq2_df['log_comments'], X).fit()\n",
    "\n",
    "print(\"\\n--- RQ2 Results ---\")\n",
    "print(f\"Spearman Rank Correlation (R): {correlation:.3f}\")\n",
    "print(f\"P-value: {p_value:.3f}\")\n",
    "# print(model.summary()) # Full model summary omitted for brevity\n",
    "print(f\"Regression Coefficient (Beta): {model.params['log_patch_size']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8574033-eff7-4072-a6ea-03ef66c5953f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51de75ca-c493-490e-b2af-12491cb44aa4",
   "metadata": {},
   "source": [
    "#### RQ1: File-Path Patterns and Acceptance Rate (Descriptive Results)\n",
    "The analysis examines how the file path category (e.g., src/, docs/, tests/) affects acceptance, comparing Agent-generated PRs (agent=True) against Human-generated PRs (agent=False)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46ccf8e6-d6e2-48a8-9498-78aa37c9d3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- RQ1 Descriptive Results (Acceptance Rate) ---\n",
      "agent          False  True \n",
      "path_category              \n",
      "Documentation    0.0    NaN\n",
      "Source Code      0.0    2.0\n",
      "Test Files       NaN    1.0\n"
     ]
    }
   ],
   "source": [
    "# Calculate acceptance rates per category and agent type\n",
    "# Outputting the descriptive table\n",
    "pivot_table = rq1_df.pivot_table(index='path_category', columns='agent', values='acceptance_rate')\n",
    "\n",
    "print(\"\\n--- RQ1 Descriptive Results (Acceptance Rate) ---\")\n",
    "print(pivot_table.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc08352b-8411-4c30-9d5c-937806defd8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
